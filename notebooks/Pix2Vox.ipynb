{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/suetin/Projects/VSCode/UltrasoundCardiacReconstruction/HeartReconstruction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suetin/Projects/VSCode/UltrasoundCardiacReconstruction/.venv/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, os, re\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle, json\n",
    "from time import time\n",
    "import logging\n",
    "import torch\n",
    "\n",
    "from src.scripts.models.Pix2Vox import Encoder, Decoder, Merger, Refiner\n",
    "from src.scripts.losses import DiceBCELoss, IoULoss\n",
    "from config import cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == torch.nn.Conv2d or type(m) == torch.nn.Conv3d or \\\n",
    "            type(m) == torch.nn.ConvTranspose2d or type(m) == torch.nn.ConvTranspose3d:\n",
    "        torch.nn.init.kaiming_normal_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            torch.nn.init.constant_(m.bias, 0)\n",
    "    elif type(m) == torch.nn.BatchNorm2d or type(m) == torch.nn.BatchNorm3d:\n",
    "        torch.nn.init.constant_(m.weight, 1)\n",
    "        torch.nn.init.constant_(m.bias, 0)\n",
    "    elif type(m) == torch.nn.Linear:\n",
    "        torch.nn.init.normal_(m.weight, 0, 0.01)\n",
    "        torch.nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_net(cfg,\n",
    "             epoch_idx=-1,\n",
    "             encoder=None,\n",
    "             decoder=None,\n",
    "             refiner=None,\n",
    "             merger=None):\n",
    "\n",
    "    # Enable the inbuilt cudnn auto-tuner to find the best algorithm to use\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # Load taxonomies of dataset\n",
    "    taxonomies = []\n",
    "    with open(cfg.DATASETS[cfg.DATASET.TEST_DATASET.upper()].TAXONOMY_FILE_PATH, encoding='utf-8') as file:\n",
    "        taxonomies = json.loads(file.read())\n",
    "    taxonomies = {t['taxonomy_id']: t for t in taxonomies}\n",
    "\n",
    "    # Set up data loader\n",
    "    if test_data_loader is None:\n",
    "        # Set up data augmentation\n",
    "        IMG_SIZE = cfg.CONST.IMG_H, cfg.CONST.IMG_W\n",
    "        CROP_SIZE = cfg.CONST.CROP_IMG_H, cfg.CONST.CROP_IMG_W\n",
    "        test_transforms = utils.data_transforms.Compose([\n",
    "            # utils.data_transforms.CenterCrop(IMG_SIZE, CROP_SIZE),\n",
    "            # utils.data_transforms.RandomBackground(cfg.TEST.RANDOM_BG_COLOR_RANGE),\n",
    "            utils.data_transforms.Normalize(mean=cfg.DATASET.MEAN, std=cfg.DATASET.STD),\n",
    "            utils.data_transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "        dataset_loader = utils.data_loaders.DATASET_LOADER_MAPPING[cfg.DATASET.TEST_DATASET](cfg)\n",
    "        test_data_loader = torch.utils.data.DataLoader(dataset=dataset_loader.get_dataset(\n",
    "            utils.data_loaders.DatasetType.TEST, cfg.CONST.N_VIEWS_RENDERING, test_transforms),\n",
    "            batch_size=1,\n",
    "            num_workers=cfg.CONST.NUM_WORKER,\n",
    "            pin_memory=True,\n",
    "            shuffle=False)\n",
    "\n",
    "    # Set up loss functions\n",
    "    # loss_func = utils.helpers.get_loss_function(cfg)\n",
    "    # Testing loop\n",
    "    n_samples = len(test_data_loader)\n",
    "    test_iou = dict()\n",
    "\n",
    "    # Switch models to evaluation mode\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    refiner.eval()\n",
    "    merger.eval()\n",
    "\n",
    "    for sample_idx, (taxonomy_id, sample_name, rendering_images, ground_truth_volume) in enumerate(test_data_loader):\n",
    "        taxonomy_id = taxonomy_id[0] if isinstance(taxonomy_id[0], str) else taxonomy_id[0].item()\n",
    "        sample_name = sample_name[0]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Get data from data loader\n",
    "            rendering_images = utils.helpers.var_or_cuda(rendering_images)\n",
    "            ground_truth_volume = utils.helpers.var_or_cuda(ground_truth_volume)\n",
    "\n",
    "            # Test the encoder, decoder, refiner and merger\n",
    "            image_features = encoder(rendering_images)\n",
    "            raw_features, generated_volume = decoder(image_features)\n",
    "\n",
    "            if cfg.NETWORK.USE_MERGER and epoch_idx >= cfg.TRAIN.EPOCH_START_USE_MERGER:\n",
    "                generated_volume = merger(raw_features, generated_volume)\n",
    "            else:\n",
    "                generated_volume = torch.mean(generated_volume, dim=1)\n",
    "            encoder_loss = loss_func(generated_volume, ground_truth_volume) * 10\n",
    "\n",
    "            if cfg.NETWORK.USE_REFINER and epoch_idx >= cfg.TRAIN.EPOCH_START_USE_REFINER:\n",
    "                generated_volume = refiner(generated_volume)\n",
    "                refiner_loss = loss_func(generated_volume, ground_truth_volume) * 10\n",
    "            else:\n",
    "                refiner_loss = encoder_loss\n",
    "\n",
    "            # IoU per sample\n",
    "            sample_iou = []\n",
    "            for th in cfg.TEST.VOXEL_THRESH:\n",
    "                _volume = torch.ge(generated_volume, th).float()\n",
    "                intersection = torch.sum(_volume.mul(ground_truth_volume)).float()\n",
    "                union = torch.sum(torch.ge(_volume.add(ground_truth_volume), 1)).float()\n",
    "                sample_iou.append((intersection / union).item())\n",
    "\n",
    "            # IoU per taxonomy\n",
    "            if taxonomy_id not in test_iou:\n",
    "                test_iou[taxonomy_id] = {'n_samples': 0, 'iou': []}\n",
    "            test_iou[taxonomy_id]['n_samples'] += 1\n",
    "            test_iou[taxonomy_id]['iou'].append(sample_iou)\n",
    "\n",
    "            # Append generated volumes to TensorBoard\n",
    "            if cfg.TEST.VOL_OR_RENDER_SAVE.lower() == 'render':\n",
    "                if test_writer and sample_idx < cfg.CONST.TEST_SAVE_NUMBER:\n",
    "                    # Volume Visualization\n",
    "                    rendering_views = utils.helpers.get_volume_views(generated_volume.cpu().numpy())\n",
    "                    test_writer.add_image('Model%02d/Reconstructed' % sample_idx, rendering_views, epoch_idx)\n",
    "                    rendering_views = utils.helpers.get_volume_views(ground_truth_volume.cpu().numpy())\n",
    "                    test_writer.add_image('Model%02d/GroundTruth' % sample_idx, rendering_views, epoch_idx)\n",
    "            elif cfg.TEST.VOL_OR_RENDER_SAVE.lower() == 'volume':\n",
    "                # if test_writer and sample_idx < cfg.CONST.TEST_SAVE_NUMBER:\n",
    "                utils.helpers.save_test_volumes_as_np(cfg, generated_volume, sample_idx, epoch_idx)\n",
    "            else:\n",
    "                raise Exception(\n",
    "                    '[FATAL] %s Invalid input for save format %s. voxels' % (dt.now(), cfg.TEST.VOL_OR_RENDER_SAVE))\n",
    "\n",
    "            # Print sample loss and IoU\n",
    "            logging.info('Test[%d/%d] Taxonomy = %s Sample = %s EDLoss = %.4f RLoss = %.4f IoU = %s' %\n",
    "                         (sample_idx + 1, n_samples, taxonomy_id, sample_name, encoder_loss.item(),\n",
    "                          refiner_loss.item(), ['%.4f' % si for si in sample_iou]))\n",
    "\n",
    "    if cfg.DIR.IOU_SAVE_PATH:\n",
    "        df = pd.DataFrame(\n",
    "            np.hstack((test_iou[taxonomy_id]['iou'], np.atleast_2d(np.max(test_iou[taxonomy_id]['iou'], axis=1)).T)),\n",
    "            columns=[*cfg.TEST.VOXEL_THRESH, 'max_iou'])\n",
    "        writer = pd.ExcelWriter(cfg.DIR.IOU_SAVE_PATH, engine='xlsxwriter')\n",
    "        df.to_excel(writer, index=False)\n",
    "        writer.save()\n",
    "\n",
    "    mean_iou = []\n",
    "    for taxonomy_id in test_iou:\n",
    "        test_iou[taxonomy_id]['iou'] = np.mean(test_iou[taxonomy_id]['iou'], axis=0)\n",
    "        mean_iou.append(test_iou[taxonomy_id]['iou'] * test_iou[taxonomy_id]['n_samples'])\n",
    "    mean_iou = np.sum(mean_iou, axis=0) / n_samples\n",
    "\n",
    "    # Print header\n",
    "    print('============================ TEST RESULTS ============================')\n",
    "    print('Taxonomy', end='\\t')\n",
    "    print('#Sample', end='\\t')\n",
    "    print('Baseline', end='\\t')\n",
    "    for th in cfg.TEST.VOXEL_THRESH:\n",
    "        print('t=%.2f' % th, end='\\t')\n",
    "    print()\n",
    "    # Print body\n",
    "    for taxonomy_id in test_iou:\n",
    "        print('%s' % taxonomies[taxonomy_id]['taxonomy_name'].ljust(8), end='\\t')\n",
    "        print('%d' % test_iou[taxonomy_id]['n_samples'], end='\\t')\n",
    "        if 'baseline' in taxonomies[taxonomy_id]:\n",
    "            # print('%.4f' % taxonomies[taxonomy_id]['baseline']['%d-view' % cfg.CONST.N_VIEWS_RENDERING], end='\\t\\t')\n",
    "            print('Ignoring baseline')\n",
    "        else:\n",
    "            print('N/a', end='\\t\\t')\n",
    "\n",
    "        for ti in test_iou[taxonomy_id]['iou']:\n",
    "            print('%.4f' % ti, end='\\t')\n",
    "        print()\n",
    "    # Print mean IoU for each threshold\n",
    "    print('Overall ', end='\\t\\t\\t\\t')\n",
    "    for mi in mean_iou:\n",
    "        print('%.4f' % mi, end='\\t')\n",
    "    print('\\n')\n",
    "\n",
    "    # Add testing results to TensorBoard\n",
    "    max_iou = np.max(mean_iou)\n",
    "\n",
    "    return max_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters in Encoder: 5576798.\n",
      "Parameters in Decoder: 55854424.\n",
      "Parameters in Refiner: 34880352.\n",
      "Parameters in Merger: 17877.\n"
     ]
    }
   ],
   "source": [
    "# Set up networks\n",
    "encoder = Encoder(cfg)\n",
    "decoder = Decoder(cfg)\n",
    "refiner = Refiner(cfg)\n",
    "merger = Merger(cfg)\n",
    "\n",
    "# logging.debug('Parameters in Encoder: %d.' % (count_parameters(encoder)))\n",
    "# logging.debug('Parameters in Decoder: %d.' % (count_parameters(decoder)))\n",
    "# logging.debug('Parameters in Refiner: %d.' % (count_parameters(refiner)))\n",
    "# logging.debug('Parameters in Merger: %d.' % (count_parameters(merger)))\n",
    "print('Parameters in Encoder: %d.' % (count_parameters(encoder)))\n",
    "print('Parameters in Decoder: %d.' % (count_parameters(decoder)))\n",
    "print('Parameters in Refiner: %d.' % (count_parameters(refiner)))\n",
    "print('Parameters in Merger: %d.' % (count_parameters(merger)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights of networks\n",
    "encoder.apply(init_weights)\n",
    "decoder.apply(init_weights)\n",
    "refiner.apply(init_weights)\n",
    "merger.apply(init_weights)\n",
    "\n",
    "# Set up solver\n",
    "if cfg.TRAIN.POLICY == 'adam':\n",
    "    encoder_solver = torch.optim.Adam(filter(lambda p: p.requires_grad, encoder.parameters()),\n",
    "                                        lr=cfg.TRAIN.ENCODER_LEARNING_RATE,\n",
    "                                        betas=cfg.TRAIN.BETAS)\n",
    "    decoder_solver = torch.optim.Adam(decoder.parameters(),\n",
    "                                        lr=cfg.TRAIN.DECODER_LEARNING_RATE,\n",
    "                                        betas=cfg.TRAIN.BETAS)\n",
    "    refiner_solver = torch.optim.Adam(refiner.parameters(),\n",
    "                                        lr=cfg.TRAIN.REFINER_LEARNING_RATE,\n",
    "                                        betas=cfg.TRAIN.BETAS)\n",
    "    merger_solver = torch.optim.Adam(merger.parameters(), lr=cfg.TRAIN.MERGER_LEARNING_RATE, betas=cfg.TRAIN.BETAS)\n",
    "else:\n",
    "    raise Exception('[FATAL] %s Unknown optimizer %s.' % (dt.now(), cfg.TRAIN.POLICY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up learning rate scheduler to decay learning rates dynamically\n",
    "encoder_lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(encoder_solver,\n",
    "                                                            milestones=cfg.TRAIN.ENCODER_LR_MILESTONES,\n",
    "                                                            gamma=cfg.TRAIN.GAMMA)\n",
    "decoder_lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(decoder_solver,\n",
    "                                                            milestones=cfg.TRAIN.DECODER_LR_MILESTONES,\n",
    "                                                            gamma=cfg.TRAIN.GAMMA)\n",
    "refiner_lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(refiner_solver,\n",
    "                                                            milestones=cfg.TRAIN.REFINER_LR_MILESTONES,\n",
    "                                                            gamma=cfg.TRAIN.GAMMA)\n",
    "merger_lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(merger_solver,\n",
    "                                                            milestones=cfg.TRAIN.MERGER_LR_MILESTONES,\n",
    "                                                            gamma=cfg.TRAIN.GAMMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up loss functions\n",
    "loss_func = torch.nn.BCELoss()   # DiceBCELoss, IoULoss\n",
    "\n",
    "# Load pretrained model if exists\n",
    "init_epoch = 0\n",
    "best_iou = -1\n",
    "best_epoch = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch_idx in range(init_epoch, cfg.TRAIN.NUM_EPOCHS):\n",
    "    # Tick / tock\n",
    "    epoch_start_time = time()\n",
    "\n",
    "    # switch models to training mode\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    merger.train()\n",
    "    refiner.train()\n",
    "\n",
    "    batch_end_time = time()\n",
    "    n_batches = len(train_data_loader)\n",
    "    for batch_idx, (taxonomy_names, sample_names, rendering_images,\n",
    "                    ground_truth_volumes) in enumerate(train_data_loader):\n",
    "\n",
    "        # Get data from data loader\n",
    "        if torch.cuda.is_available():\n",
    "            rendering_images = rendering_images.cuda(non_blocking=True)\n",
    "            ground_truth_volumes = ground_truth_volumes.cuda(non_blocking=True)\n",
    "\n",
    "        # Train the encoder, decoder, refiner, and merger\n",
    "        image_features = encoder(rendering_images)\n",
    "        raw_features, generated_volumes = decoder(image_features)\n",
    "\n",
    "        if cfg.NETWORK.USE_MERGER and epoch_idx >= cfg.TRAIN.EPOCH_START_USE_MERGER:\n",
    "            generated_volumes = merger(raw_features, generated_volumes)\n",
    "        else:\n",
    "            generated_volumes = torch.mean(generated_volumes, dim=1)\n",
    "        encoder_loss = loss_func(generated_volumes, ground_truth_volumes) * 10\n",
    "\n",
    "        if cfg.NETWORK.USE_REFINER and epoch_idx >= cfg.TRAIN.EPOCH_START_USE_REFINER:\n",
    "            generated_volumes = refiner(generated_volumes)\n",
    "            refiner_loss = loss_func(generated_volumes, ground_truth_volumes) * 10\n",
    "        else:\n",
    "            refiner_loss = encoder_loss\n",
    "\n",
    "        # Gradient decent\n",
    "        encoder.zero_grad()\n",
    "        decoder.zero_grad()\n",
    "        refiner.zero_grad()\n",
    "        merger.zero_grad()\n",
    "\n",
    "        if cfg.NETWORK.USE_REFINER and epoch_idx >= cfg.TRAIN.EPOCH_START_USE_REFINER:\n",
    "            encoder_loss.backward(retain_graph=True)\n",
    "            refiner_loss.backward()\n",
    "        else:\n",
    "            encoder_loss.backward()\n",
    "\n",
    "        encoder_solver.step()\n",
    "        decoder_solver.step()\n",
    "        refiner_solver.step()\n",
    "        merger_solver.step()\n",
    "\n",
    "        # Append loss to average metrics\n",
    "        # encoder_losses.update(encoder_loss.item())\n",
    "        # refiner_losses.update(refiner_loss.item())\n",
    "        # Append loss to TensorBoard\n",
    "        # n_itr = epoch_idx * n_batches + batch_idx\n",
    "        # train_writer.add_scalar('EncoderDecoder/BatchLoss', encoder_loss.item(), n_itr)\n",
    "        # train_writer.add_scalar('Refiner/BatchLoss', refiner_loss.item(), n_itr)\n",
    "\n",
    "        # Tick / tock\n",
    "        # batch_time.update(time() - batch_end_time)\n",
    "        # batch_end_time = time()\n",
    "        # logging.info(\n",
    "        #     '[Epoch %d/%d][Batch %d/%d] BatchTime = %.3f (s) DataTime = %.3f (s) EDLoss = %.4f RLoss = %.4f' %\n",
    "        #     (epoch_idx + 1, cfg.TRAIN.NUM_EPOCHS, batch_idx + 1, n_batches, batch_time.val, data_time.val,\n",
    "        #         encoder_loss.item(), refiner_loss.item()))\n",
    "\n",
    "    # Adjust learning rate\n",
    "    encoder_lr_scheduler.step()\n",
    "    decoder_lr_scheduler.step()\n",
    "    refiner_lr_scheduler.step()\n",
    "    merger_lr_scheduler.step()\n",
    "\n",
    "    # Append epoch loss to TensorBoard\n",
    "    # train_writer.add_scalar('EncoderDecoder/EpochLoss', encoder_losses.avg, epoch_idx + 1)\n",
    "    # train_writer.add_scalar('Refiner/EpochLoss', refiner_losses.avg, epoch_idx + 1)\n",
    "\n",
    "    # Tick / tock\n",
    "    epoch_end_time = time()\n",
    "    print('[Epoch %d/%d] EpochTime = %.3f (s) EDLoss = %.4f RLoss = %.4f' % (epoch_idx + 1, cfg.TRAIN.NUM_EPOCHS, epoch_end_time - epoch_start_time, ))\n",
    "    # logging.info('[Epoch %d/%d] EpochTime = %.3f (s) EDLoss = %.4f RLoss = %.4f' %\n",
    "    #                 (epoch_idx + 1, cfg.TRAIN.NUM_EPOCHS, epoch_end_time - epoch_start_time, encoder_losses.avg,\n",
    "    #                 refiner_losses.avg))\n",
    "\n",
    "    # Update Rendering Views\n",
    "    if cfg.TRAIN.UPDATE_N_VIEWS_RENDERING:\n",
    "        n_views_rendering = random.randint(1, cfg.CONST.N_VIEWS_RENDERING)\n",
    "        train_data_loader.dataset.set_n_views_rendering(n_views_rendering)\n",
    "        logging.info('Epoch [%d/%d] Update #RenderingViews to %d' %\n",
    "                        (epoch_idx + 2, cfg.TRAIN.NUM_EPOCHS, n_views_rendering))\n",
    "\n",
    "    # Validate the training models\n",
    "    iou = test_net(cfg, epoch_idx + 1, val_data_loader, val_writer, encoder, decoder, refiner, merger)\n",
    "\n",
    "    # Save weights to file\n",
    "    if (epoch_idx + 1) % cfg.TRAIN.SAVE_FREQ == 0 or iou > best_iou:\n",
    "        file_name = 'checkpoint-epoch-%03d.pth' % (epoch_idx + 1)\n",
    "        if iou > best_iou:\n",
    "            best_iou = iou\n",
    "            best_epoch = epoch_idx\n",
    "            file_name = 'checkpoint-best.pth'\n",
    "\n",
    "        output_path = os.path.join(cfg.DIR.CHECKPOINTS, file_name)\n",
    "        if not os.path.exists(cfg.DIR.CHECKPOINTS):\n",
    "            os.makedirs(cfg.DIR.CHECKPOINTS)\n",
    "\n",
    "        with open(os.path.join(cfg.DIR.OUT_PATH, 'train_test_config.json'), 'w') as fp:\n",
    "            json.dump(cfg, fp, indent=4)\n",
    "            fp.close()\n",
    "\n",
    "        checkpoint = {\n",
    "            'epoch_idx': epoch_idx,\n",
    "            'best_iou': best_iou,\n",
    "            'best_epoch': best_epoch,\n",
    "            'encoder_state_dict': encoder.state_dict(),\n",
    "            'decoder_state_dict': decoder.state_dict(),\n",
    "        }\n",
    "        if cfg.NETWORK.USE_REFINER:\n",
    "            checkpoint['refiner_state_dict'] = refiner.state_dict()\n",
    "        if cfg.NETWORK.USE_MERGER:\n",
    "            checkpoint['merger_state_dict'] = merger.state_dict()\n",
    "\n",
    "        torch.save(checkpoint, output_path)\n",
    "        logging.info('Saved checkpoint to %s ...' % output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
